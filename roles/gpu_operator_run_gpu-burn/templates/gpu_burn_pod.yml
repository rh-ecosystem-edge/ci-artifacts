apiVersion: v1
kind: Pod
metadata:
  labels:
    app: gpu-burn
  name: gpu-burn-{{ gpu_node_name }}
  namespace: gpu-burn
spec:
  restartPolicy: Never
  # force the name of the node in which this pod should run
  nodeName: "{{ gpu_node_name }}"
  securityContext:
    runAsNonRoot: true
  containers:
  - image: quay.io/edge-infrastructure/gpu-burn:latest
    imagePullPolicy: Always
    securityContext:
      runAsUser: 1001
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      seccompProfile:
        type: "RuntimeDefault"
    name: gpu-burn-ctr
    command:
    - /bin/entrypoint.sh
    volumeMounts:
    - name: entrypoint
      mountPath: /bin/entrypoint.sh
      readOnly: true
      subPath: entrypoint.sh
    env:
    - name: GPU_BURN_TIME
      value: "{{ gpu_burn_time }}"
    resources:
      limits:
        # '0' means 'get access to all the GPUs of the local node'
        nvidia.com/gpu: 0
  volumes:
  - name: entrypoint
    configMap:
      defaultMode: 0755
      name: gpu-burn-entrypoint
